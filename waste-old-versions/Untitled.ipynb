{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import collections \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import re\n",
    "import urllib2\n",
    "#import regex\n",
    "#import locale\n",
    "#import usaddress\n",
    "#import geograpy\n",
    "#import nltk\n",
    "from pyquery import PyQuery as pq\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global data storage\n",
    "climbsjson = collections.defaultdict(dict) # double nested dict\n",
    "usersjson = collections.defaultdict(dict) # double nested dict\n",
    "ucjson = collections.defaultdict(dict) #double nested dict\n",
    "\n",
    " # sub-functions and initializations for user/climb_scrape_func-s\n",
    "\n",
    "def parse_climb_link(href_link):\n",
    "    return href_link.split('/')[-1], href_link.split('/')[-2]\n",
    "\n",
    "def parse_user_link(href_link):\n",
    "    return href_link.split('/')[-1], href_link.split('/')[-3]\n",
    "\n",
    "# 16. get star info from td pairs for climb parser\n",
    "def star_quality_func(td1, td2, climb_id):\n",
    "    user_id, user_name = parse_user_link(td1('a').attr('href'))\n",
    "    rating = int(re.search(r'starsHtml\\(([0-5]),', \n",
    "                       td2('script').text()).group(1)) - 1\n",
    "    ucjson[climb_id + \"_\" + user_id][\"user_id\"] = user_id\n",
    "    ucjson[climb_id + \"_\" + user_id][\"climb_id\"] = climb_id\n",
    "    ucjson[climb_id + \"_\" + user_id][\"star_rating\"] = rating\n",
    "\n",
    "# 19. get sugg_rate info from td pairs\n",
    "def sugg_rating_func(td1, td2, climb_id):\n",
    "    user_id, user_name = parse_user_link(td1('a').attr('href'))\n",
    "    ucjson[climb_id + \"_\" + user_id][\"user_id\"] = user_id\n",
    "    ucjson[climb_id + \"_\" + user_id][\"climb_id\"] = climb_id\n",
    "    \n",
    "    for key, regex in diff_regexes.iteritems():\n",
    "        temp = re.search(regex, td2.text())\n",
    "        if  temp != None:\n",
    "            ucjson[climb_id + \"_\" + user_id][\"sugg_\" + key] = temp.group()\n",
    "        else:\n",
    "            ucjson[climb_id + \"_\" + user_id][\"sugg_\" + key] = 0\n",
    "\n",
    "aid_re = r'(A[0-5])|(C[0-5])[-,+]?'\n",
    "boulder_re = r'V\\d\\d?[-,+]?'\n",
    "ice_re = r'WI[1-6][+,-]?'\n",
    "mixed_re = r'M\\d\\d?[+,-]?'\n",
    "rock_re = r'5.\\d\\d?(([a-d]/[a-d])|([a-d]))?[+,-]?'\n",
    "\n",
    "diff_regexes = {\"aid_grade\": aid_re, \"boulder_grade\": boulder_re, \n",
    "               \"ice_grade\": ice_re, \"mixed_grade\": mixed_re, \n",
    "               \"rock_grade\": rock_re}\n",
    "\n",
    "user_type_regexes = {\"Trad\": rock_re, \"Sport\": rock_re, \n",
    "                     \"Boulders\": boulder_re, \"Aid\": aid_re, \n",
    "                     \"Ice\": ice_re, \"Mixed\": mixed_re}\n",
    "\n",
    "typesdict = {\"trad\": 0, \"alpine\": 0, \"ice\": 0, \"sport\": 0,\n",
    "        \"boulder\": 0, \"aid\": 0, \"mixed\": 0, \"TR,\": 0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def climb_scrape_func(climb_link, state='undef', lat=0, lng=0):\n",
    "    \n",
    "    # initialize local climbdict\n",
    "    climbdict = {\"climb_id\": 0, \"climb_name\": 'undef',\n",
    "             \"avg_stars\": 0, \"pitches\": 0, \"feet\": 0, \"climb_link\": climb_link}\n",
    "    \n",
    "    # add latittude and logitude and state\n",
    "    climbdict[\"latitude\"] = lat\n",
    "    climbdict[\"longitude\"] = lng\n",
    "    climbdict[\"state\"] = state\n",
    "        \n",
    "    # 1. get keys\n",
    "    climb_id, climb_name = parse_climb_link(climb_link)\n",
    "    climbdict[\"climb_id\"] = climb_id\n",
    "    climbdict[\"climb_name\"] = climb_name\n",
    "    \n",
    "    # climb already scraped, then abort\n",
    "    if len(climbsjson[climb_id]) != 0:\n",
    "        return\n",
    "    \n",
    "    # get page into pyquery object\n",
    "    climb_req=requests.get(climb_link)\n",
    "    climb_=pq(climb_req.text)\n",
    "\n",
    "    # 0. get areas\n",
    "    climb_loc = climb_(\"#navBox\").find('a')\n",
    "    for i in range(0, len(climb_loc)):\n",
    "        climbdict[\"area_\" + str(i)] = (climb_loc.eq(i).attr('href'))\n",
    "    \n",
    "    # 2. separate climb div\n",
    "    climb_div = climb_('div#rspCol800')\n",
    "    \n",
    "    # 3. get climb summary div\n",
    "    climb_summstats = climb_div('div.rspCol[style=\"max-width:500px;\"]')\n",
    "    \n",
    "    # 4. get grade ratings\n",
    "    climb_summstats_subtitle = climb_summstats('h3')\n",
    "    \n",
    "    for key, regex in diff_regexes.items():\n",
    "        temp = re.search(regex, climb_summstats_subtitle.text())\n",
    "        if  temp != None:\n",
    "            climbdict[\"guide_\" + key] = temp.group()\n",
    "        else:\n",
    "            climbdict[\"guide_\" + key] = 0\n",
    "            \n",
    "    # 5. get average star rating\n",
    "    average_stars_script_html = climb_summstats('span#routeStars')('script').html()\n",
    "    average_stars_regexobj = re.search(r'[1-5]\\.\\d\\d?\\d?\\d?', \n",
    "                                       average_stars_script_html)\n",
    "    if average_stars_regexobj != None:     \n",
    "        avg_stars = float(average_stars_regexobj.group()) - 1\n",
    "        climbdict[\"avg_stars\"] = avg_stars\n",
    "    else:\n",
    "        avg_stars = 0\n",
    "        \n",
    "    # 6. get rows of table\n",
    "    climb_summstats_table = climb_summstats('table')\n",
    "\n",
    "    # get climb types, pitches, feet, grade\n",
    "    climb_summstats_type_cell = climb_summstats_table(\"td:contains('Type:')\")\n",
    "    # 7. get climb types\n",
    "    if climb_summstats_type_cell:\n",
    "        climb_summstats_type_text = climb_summstats_type_cell.next().text()\n",
    "        for key in typesdict:\n",
    "            if re.search(r'{}'.format(key), \n",
    "                        climb_summstats_type_text, \n",
    "                        flags = re.I) != None:\n",
    "                climbdict[\"type_\" + key] = 1\n",
    "            else:\n",
    "                climbdict[\"type_\" + key] = 0\n",
    "\n",
    "        # 8. get the number of pitches\n",
    "        pitches_regobj = re.search(r'(\\d\\d?) pitch(es)?', \n",
    "                        climb_summstats_type_text, \n",
    "                        flags = re.I)\n",
    "        if pitches_regobj:\n",
    "            climbdict[\"pitches\"] = int(pitches_regobj.group(1))\n",
    "        else:\n",
    "            climbdict[\"pitches\"] = None\n",
    "\n",
    "        # 9. get number of feet\n",
    "        feet_regobj = re.search(r\" (\\d\\d?\\d?\\d?\\d?)'\", \n",
    "                        climb_summstats_type_text, \n",
    "                        flags = re.I)\n",
    "        if feet_regobj:\n",
    "            climbdict[\"feet\"] = int(feet_regobj.group(1))\n",
    "        else:\n",
    "            climbdict[\"feet\"] = None\n",
    "\n",
    "        # 10. get commitment grade\n",
    "        grade_regobj = re.search(r'Grade ([I,II,III,IV,V,VI])', \n",
    "                        climb_summstats_type_text, \n",
    "                        flags = re.I)\n",
    "        if grade_regobj:\n",
    "            climbdict[\"grade\"] = grade_regobj.group(1)\n",
    "        else:\n",
    "            climbdict[\"grade\"] = None\n",
    "\n",
    "    # 11. get concensus rating\n",
    "    climb_summstats_table_consensus_cell = climb_summstats_table(\"td:contains('Consensus')\")\n",
    "    if climb_summstats_table_consensus_cell:\n",
    "        climb_summstats_table_consensus_text = climb_summstats_table_consensus_cell.next().text()\n",
    "        for key, regex in diff_regexes.iteritems():\n",
    "            temp = re.search(regex,climb_summstats_table_consensus_text)\n",
    "            if  temp != None:\n",
    "                climbdict[\"concensus_\" + key] = temp.group()\n",
    "            else:\n",
    "                climbdict[\"concensus_\" + key] = 0\n",
    "\n",
    "    # 12. get FA year\n",
    "    climb_summstats_table_fa_cell = climb_summstats_table(\"td:contains('FA:')\")\n",
    "    if climb_summstats_table_fa_cell:\n",
    "        climb_summstats_table_fa_text = climb_summstats_table_fa_cell.next().text()\n",
    "        fa_regobj = re.search(r\"([18,19,20]\\d\\d\\d)\",climb_summstats_table_fa_text)\n",
    "        if fa_regobj:\n",
    "            climbdict[\"fa_year\"] = int(fa_regobj.group(1))\n",
    "        else:\n",
    "            climbdict[\"fa_year\"] = None\n",
    "    \n",
    "    # 13. get page views\n",
    "    climb_summstats_table_pv_cell = climb_summstats_table(\"td:contains('Page Views')\")\n",
    "    if climb_summstats_table_pv_cell:\n",
    "        climb_summstats_table_pv_text = climb_summstats_table_pv_cell.next().text()    \n",
    "        views_regobj = re.search(r\"\\d?\\d?\\d?,?\\d?\\d\\d\",climb_summstats_table_pv_text )\n",
    "        if views_regobj:\n",
    "            climbdict[\"page_views\"] = int(views_regobj.group().replace(',',''))\n",
    "        else:\n",
    "            climbdict[\"page_views\"] = None\n",
    "        \n",
    "    # 14. get detailed users-climb page\n",
    "    stats_link = (\"http://mountainproject.com/scripts/ShowObjectStats.php?id=%s\"\n",
    "                  % climbdict['climb_id'])\n",
    "    climb_stats_req=requests.get(stats_link)\n",
    "    stats_=pq(climb_stats_req.text)\n",
    "\n",
    "    # 15. get star quality votes tables\n",
    "    stats_stars_table = stats_(\"span:contains('Star Quality Votes')\").next().next().find('tr')  \n",
    "    \n",
    "    # 17. iterate through stars table and populate ucjson \n",
    "    for i in range(0, len(stats_stars_table)):\n",
    "        tds = stats_stars_table.eq(i).find('td')\n",
    "        if len(tds) > 0:\n",
    "            star_quality_func(tds.eq(0),tds.eq(1), climb_id)\n",
    "            if len(tds) == 4:\n",
    "                star_quality_func(tds.eq(2),tds.eq(3), climb_id)\n",
    "                \n",
    "    # 18. get suggested ratings rows\n",
    "    stats_sugg_table = stats_(\"span:contains('Suggested Ratings')\").next().next().find('tr')  \n",
    "    \n",
    "    # 20. iterate through suggested ratings table and populate ucjson \n",
    "    for i in range(0, len(stats_sugg_table)):\n",
    "        tds = stats_sugg_table.eq(i).find('td')\n",
    "        if len(tds) > 1:\n",
    "            sugg_rating_func(tds.eq(0),tds.eq(1), climb_id)\n",
    "            if len(tds) == 4:\n",
    "                sugg_rating_func(tds.eq(2),tds.eq(3), climb_id)\n",
    "                \n",
    "    # 21. \n",
    "    stats_ticks_table = stats_(\"span:contains('Ticks')\").next().next().find('tr')  \n",
    "\n",
    "    # 22. iterate through ticks ratings table and populate ucjson \n",
    "    # this might require a tweek if dates are ever listed as (\"\\d\\d? days ago\")\n",
    "    dates_wrong = 0\n",
    "    for i in range(0, len(stats_ticks_table)):\n",
    "        tds = stats_ticks_table.eq(i).find('td')\n",
    "        if len(tds) == 3:\n",
    "            user_id, user_name = parse_user_link(tds.eq(0)('a').attr('href'))\n",
    "            ucjson[climb_id + \"_\" + user_id][\"user_id\"] = user_id\n",
    "            ucjson[climb_id + \"_\" + user_id][\"climb_id\"] = climb_id\n",
    "            try: \n",
    "                date = time.strptime(tds.eq(1).text(), \"%b %d, %Y\")\n",
    "                ucjson[climb_id + \"_\" + user_id][\"tick_date\"] = date\n",
    "                ucjson[climb_id + \"_\" + user_id][\"ticked\"] = 1\n",
    "            except ValueError:\n",
    "                dates_wrong += 1\n",
    "                \n",
    "    # add climbdict to climbsjson\n",
    "    climbsjson[climb_id] = climbdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "climb_scrape_func(\"https://www.mountainproject.com/v/intertwine/105905517\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'105905517': {'area_0': '/destinations/',\n",
       "              'area_1': '/v/massachusetts/105908062',\n",
       "              'area_2': '/v/leominster-area/108175250',\n",
       "              'area_3': '/v/crow-hill/105905492',\n",
       "              'area_4': '/v/main-face/105905514',\n",
       "              'avg_stars': 3.2916999999999996,\n",
       "              'climb_id': '105905517',\n",
       "              'climb_link': 'https://www.mountainproject.com/v/intertwine/105905517',\n",
       "              'climb_name': 'intertwine',\n",
       "              'concensus_aid_grade': 0,\n",
       "              'concensus_boulder_grade': 0,\n",
       "              'concensus_ice_grade': 0,\n",
       "              'concensus_mixed_grade': 0,\n",
       "              'concensus_rock_grade': u'5.8',\n",
       "              'fa_year': None,\n",
       "              'feet': 45,\n",
       "              'grade': None,\n",
       "              'guide_aid_grade': 0,\n",
       "              'guide_boulder_grade': 0,\n",
       "              'guide_ice_grade': 0,\n",
       "              'guide_mixed_grade': 0,\n",
       "              'guide_rock_grade': u'5.8',\n",
       "              'latitude': 0,\n",
       "              'longitude': 0,\n",
       "              'page_views': 7354,\n",
       "              'pitches': 1,\n",
       "              'state': 'undef',\n",
       "              'type_TR,': 1,\n",
       "              'type_aid': 0,\n",
       "              'type_alpine': 0,\n",
       "              'type_boulder': 0,\n",
       "              'type_ice': 0,\n",
       "              'type_mixed': 0,\n",
       "              'type_sport': 0,\n",
       "              'type_trad': 1}})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climbsjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "climbdict = {}\n",
    "# get page into pyquery object\n",
    "climb_req=requests.get(\"https://www.mountainproject.com/v/intertwine/105905517\")\n",
    "climb_=pq(climb_req.text)\n",
    "\n",
    "# 0. get areas\n",
    "climb_loc = climb_(\"#navBox\").find('a')\n",
    "for i in range(0, len(climb_loc)):\n",
    "    climbdict[\"area_\" + str(i)] = (climb_loc.eq(i).attr('href'))\n",
    "\n",
    "# 2. separate climb div\n",
    "climb_div = climb_('div#rspCol800')\n",
    "\n",
    "# 3. get climb summary div\n",
    "climb_summstats = climb_div('div.rspCol[style=\"max-width:500px;\"]')\n",
    "\n",
    "# 4. get grade ratings\n",
    "climb_summstats_subtitle = climb_summstats('h3')\n",
    "\n",
    "for key, regex in diff_regexes.items():\n",
    "    temp = re.search(regex, climb_summstats_subtitle.text())\n",
    "    if  temp != None:\n",
    "        climbdict[\"guide_\" + key] = temp.group()\n",
    "    else:\n",
    "        climbdict[\"guide_\" + key] = 0\n",
    "\n",
    "# 5. get average star rating\n",
    "average_stars_script_html = climb_summstats('span#routeStars')('script').html()\n",
    "average_stars_regexobj = re.search(r'[1-5]\\.\\d\\d?\\d?\\d?', \n",
    "                                   average_stars_script_html)\n",
    "if average_stars_regexobj != None:     \n",
    "    avg_stars = float(average_stars_regexobj.group()) - 1\n",
    "    climbdict[\"avg_stars\"] = avg_stars\n",
    "else:\n",
    "    avg_stars = 0\n",
    "\n",
    "# 6. get rows of table\n",
    "climb_summstats_table = climb_summstats('table')\n",
    "\n",
    "# 7. get climb types\n",
    "climb_summstats_type_row = climb_summstats_table(\"tr:contains('Type')\")\n",
    "for key in typesdict:\n",
    "    if re.search(r'{}'.format(key), \n",
    "                climb_summstats_type_row.text(), \n",
    "                flags = re.I) != None:\n",
    "        climbdict[\"type_\" + key] = 1\n",
    "    else:\n",
    "        climbdict[\"type_\" + key] = 0\n",
    "\n",
    "# 8. get the number of pitches\n",
    "pitches_regobj = re.search(r'(\\d\\d?) pitches', \n",
    "                climb_summstats_table.eq(0).text(), \n",
    "                flags = re.I)\n",
    "if pitches_regobj:\n",
    "    climbdict[\"pitches\"] = int(pitches_regobj.group(1))\n",
    "\n",
    "# 9. get number of feet\n",
    "feet_regobj = re.search(r\" (\\d\\d?\\d?\\d?\\d?)'\", \n",
    "                climb_summstats_table.eq(0).text(), \n",
    "                flags = re.I)\n",
    "if feet_regobj:\n",
    "    climbdict[\"feet\"] = int(feet_regobj.group(1))\n",
    "\n",
    "# 10. get number of feet\n",
    "grade_regobj = re.search(r'Grade ([I,II,III,IV,V,VI])', \n",
    "                climb_summstats_table.eq(0).text(), \n",
    "                flags = re.I)\n",
    "if grade_regobj:\n",
    "    climbdict[\"grade\"] = grade_regobj.group(1)\n",
    "\n",
    "# 11. get concensus rating\n",
    "for key, regex in diff_regexes.iteritems():\n",
    "    temp = re.search(regex,climb_summstats_table.eq(1).text())\n",
    "    if  temp != None:\n",
    "        climbdict[\"concensus_\" + key] = temp.group()\n",
    "    else:\n",
    "        climbdict[\"concensus_\" + key] = 0\n",
    "\n",
    "# 12. get FA year\n",
    "fa_regobj = re.search(r\"([18,19,20]\\d\\d\\d)\",climb_summstats_table.eq(2).text())\n",
    "if fa_regobj:\n",
    "    climbdict[\"fa_year\"] = int(fa_regobj.group(1))\n",
    "\n",
    "# 13. get page views\n",
    "views_regobj = re.search(r\"\\d?\\d?\\d?,?\\d?\\d\\d\",climb_summstats_table.eq(3).text())\n",
    "if views_regobj:\n",
    "    climbdict[\"page_views\"] = int(views_regobj.group().replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climb_summstats_type_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Trad, TR, 1 pitch, 45'\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climb_summstats_table(\"td:contains('Type:')\").next().text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
